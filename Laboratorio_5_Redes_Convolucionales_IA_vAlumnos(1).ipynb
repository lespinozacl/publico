{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lespinozacl/publico/blob/master/Laboratorio_5_Redes_Convolucionales_IA_vAlumnos(1).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BGtjkEoXRrUA"
      },
      "source": [
        "# **Diplomado IA: Aprendizaje Profundo I - Parte 1**. <br> Práctico Clase 5: Redes Convolucionales\n",
        "---\n",
        "---\n",
        "\n",
        "**Profesores:**\n",
        "- Alain Raymond\n",
        "- Miguel Fadic\n",
        "- Gabriel Sepúlveda\n",
        "- Álvaro Soto\n",
        "\n",
        "**Ayudante:**\n",
        "- Andres Villa\n",
        "---\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7-d4JrMVRYVJ"
      },
      "source": [
        "El siguiente práctico se debe realizar de forma individual. El formato de entregar es el **archivo .ipynb con todas las celdas ejecutadas**. Las secciones donde se planteen preguntas de forma explícita, deben ser respondida en celdas de texto, y no se aceptará solo el _output_ de una celda de código como respuesta.\n",
        "\n",
        "**Nombre alumno:**\n",
        "\n",
        "El siguiente práctico contendrá 1 o más actividades a realizar. Algunas actividades corresponderán a escribir código y otras a responder preguntas.\n",
        "\n",
        "Antes de responder, se recomienda **fuertemente** revisar las secciones previas donde se desarrollan los ejemplos, dado que algunas de las actividades pueden ser completadas reutilizando el mismo código.\n",
        "\n",
        "**Fecha de entrega:** viernes 28 de julio de 2023, 23:59 hrs.\n",
        "\n",
        "---\n",
        "**IMPORTANTE:** habrá un bonus de 1 décima para todos aquellos alumnos/as que muestren buen orden en sus respuestas (esto aplica a legibilidad de código, buena redacción, formalidad, organización del jupyter notebook, seguimiento de instrucciones, etc). El criterio lo pondrá cada ayudante corrector. La nota máxima obtenible en el laboratorio es 7.0"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kS6sFsBAEqYb"
      },
      "source": [
        "## Introducción a Google Colab\n",
        "\n",
        "Google Colab es una herramienta gratuita (para cualquier persona con una cuenta Gmail), para poder programar de forma interactiva en Python.\n",
        "\n",
        "Ventajas:\n",
        "* Podemos programar de forma interactiva viendo los resultados de nuestro código paso a paso.\n",
        "* No requiere que tengamos nada instalado en nuestro computador excepto un browser compatible como Google Chrome, Mozilla Firefox o Microsoft Edge.\n",
        "* Podemos experimentar en un ambiente seguro con cantidad razonable de recursos y sin ninguna posibilidad de arruinar nuestros computadores.\n",
        "* Tenemos acceso a GPUs (¡gratis!) para nuestros cálculos.\n",
        "\n",
        "Si quieres ahondar más en profundidad en Colab, te recomendamos el siguiente tutorial: https://www.tutorialspoint.com/google_colab/google_colab_tutorial.pdf.\n",
        "\n",
        "\n",
        "¡Probemos algunas cosas rápidas!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pmYcuKWcG5sP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f324e624-bdf5-48a1-f629-cdbd9f9edceb"
      },
      "source": [
        "5 + 3"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "8"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QxEoxe9iLBWy"
      },
      "source": [
        "a = 0"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZAE0vB-tKUOM"
      },
      "source": [
        "a  = a + 3"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vQac6o-LKXfH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "895527f6-692b-4a48-9a95-cf81579fce3c"
      },
      "source": [
        "a"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IRiZ2ZgBKdxa"
      },
      "source": [
        "A diferencia de cuando programamos normalmente, en Colab cada comando ejecutado depende de todos los otros comandos que hayamos ejecutado. Esta ejecución no tiene por qué ser secuencial."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "392MooCwBNYk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7f347350-435a-42f6-a805-f120d418a431"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y2Dddg6iLPrp"
      },
      "source": [
        "### Activar la GPU\n",
        "Eventualmente querremos entrenar un modelo profundo, por lo que necesitaremos una GPU para entrenarlo. Colab nos provee una. Sin embargo, debemos activar el uso de la GPU en el ambiente Colab.\n",
        "\n",
        "Debemos ir al menú superior, elegir \"Runtime\" --> \"Change Runtime Type\". En el dropdown de \"Hardware Accelerator\" cambiaremos la opción a \"GPU\". Esto basta hacerlo una sola vez por cada notebook que tengamos, esta opción queda guardada entre sesiones."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TH6c7A4Ci3P-"
      },
      "source": [
        "### Subir archivos\n",
        "\n",
        "A la izquierda de la ventana podrán ver un ícono de una carpeta. Si hacen click en él, podrán visualizar la interfaz de archivos de Colab. Esta les muestra que archivos hay actualmente en su espacio de trabajo y les permite subir archivos desde su computador, o incluso conectarse con su cuenta de Google Drive para tener acceso a sus archivos. Para subir archivos sólo deben hacer click en el botón que muestra un archivo con una flecha hacia arriba. Para conectar con su cuenta de Google Drive sólo deben hacer click en el botón de más a la derecha con el símbolo de Drive. Sus archivos de Drive quedan accesibles en la carpeta 'drive'.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nI-pmePFjv6j"
      },
      "source": [
        "### Instalar Librerías\n",
        "\n",
        "Colab trabaja sobre un ambiente Linux, por lo que ustedes pueden también ejecutar comandos de Linux en caso de ser necesario. Para ello sólo deben anteponer el comando con un '!'.\n",
        "\n",
        "**Ejemplos:**\n",
        "Por ejemplo, el siguiente comando instala la librería *transformers* de Python."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hNMoHLVHkJxj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b866c1c7-abec-40c3-f520-06311c5967f9"
      },
      "source": [
        "!pip install transformers"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting transformers\n",
            "  Downloading transformers-4.34.1-py3-none-any.whl (7.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.7/7.7 MB\u001b[0m \u001b[31m57.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.12.4)\n",
            "Collecting huggingface-hub<1.0,>=0.16.4 (from transformers)\n",
            "  Downloading huggingface_hub-0.18.0-py3-none-any.whl (301 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m302.0/302.0 kB\u001b[0m \u001b[31m31.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.23.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2023.6.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n",
            "Collecting tokenizers<0.15,>=0.14 (from transformers)\n",
            "  Downloading tokenizers-0.14.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.8/3.8 MB\u001b[0m \u001b[31m68.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting safetensors>=0.3.1 (from transformers)\n",
            "  Downloading safetensors-0.4.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m62.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->transformers) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->transformers) (4.5.0)\n",
            "Collecting huggingface-hub<1.0,>=0.16.4 (from transformers)\n",
            "  Downloading huggingface_hub-0.17.3-py3-none-any.whl (295 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m295.0/295.0 kB\u001b[0m \u001b[31m22.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2023.7.22)\n",
            "Installing collected packages: safetensors, huggingface-hub, tokenizers, transformers\n",
            "Successfully installed huggingface-hub-0.17.3 safetensors-0.4.0 tokenizers-0.14.1 transformers-4.34.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jjgnBz5Yk25J"
      },
      "source": [
        "Crear un archivo con *touch*:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q1Ie7MWWkoih"
      },
      "source": [
        "!touch test.txt"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RspLcxHekxAl"
      },
      "source": [
        "Copiar un archivo:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z93oCC9YkrId"
      },
      "source": [
        "!cp test.txt test1.txt"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jm8gnsUek_HM"
      },
      "source": [
        "Eliminar archivos:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F21-rmqTktlc"
      },
      "source": [
        "!rm *.txt"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0w-GqJDykWG9"
      },
      "source": [
        "Un comentario final: hay ciertos comandos que no van a poder ejecutar pues están deshabilitados, pero para todos los fines prácticos, no deberían tener muchas restricciones."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c8WDcMIPEGRa"
      },
      "source": [
        "## Parte 1: Creando AlexNet\n",
        "\n",
        "En la siguiente sección vamos a ver cómo traducimos todas esas piezas que vimos en la clase de Redes Convolucionales (filtros, *stride*, *padding*, etc.) en código práctico en Python."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kT5cY0_aE4cO"
      },
      "source": [
        "Recordemos la estructura de AlexNet:\n",
        "\n",
        "\n",
        "![alt text](https://www.researchgate.net/profile/Sherif_Shehata2/publication/308880040/figure/fig3/AS:413548556636165@1475609067864/An-illustration-of-the-architecture-of-AlexNet-deep-convolutional-neural-network.png)\n",
        "\n",
        "Algunos comentarios:\n",
        "\n",
        "* Si no se menciona el stride en la capa, se asume que es de 1.\n",
        "* Sólo hay Max Pooling en las capas que se indica. Si hay usa *stride* de 2 y kernel de (3,3).\n",
        "* El *padding* por capa es:\n",
        "\n",
        "\n",
        "\n",
        ">Capa | Padding\n",
        ">--- | ---\n",
        ">Conv1 | 2\n",
        ">Conv2 | 2\n",
        ">Conv3 | 1\n",
        ">Conv4 | 1\n",
        ">Conv5 | 1\n",
        "\n",
        "¡Empecemos a armarlo!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9Xl8S2FhFFA6"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn           # Esto es PyTorch y su módulo de Redes Neuronales\n",
        "\n",
        "class AlexNet(nn.Module):                   # Esta clase representa nuestro modelo\n",
        "\n",
        "    def __init__(self):   # Constructor, aquí armamos las piezas de nuestra red\n",
        "        super(AlexNet, self).__init__()\n",
        "        # Bloques Convolucionales\n",
        "        # Recordemos que los Bloques Convolucionales van a estar hechos de 3\n",
        "        # elementos: Convolución, Pooling y Activación.\n",
        "        # En este caso usaremos Convoluciones 2d, Max Pooling y ReLU\n",
        "\n",
        "        # Input = 3x 224 x 224 Output = 96 x 55 x 55 --> Max Pool = 96 x 27 x 27\n",
        "        self.conv1 = nn.Sequential(\n",
        "            nn.Conv2d(                           # Todo esto define a la Convolución\n",
        "                      in_channels=3,             # Filtros/Canales de Entrada (RGB)\n",
        "                      out_channels=96,           # Filtros/Canales de Salida\n",
        "                      kernel_size=(11,11),       # Tamaño de la Convolución\n",
        "                      stride=(4,4),              # Stride\n",
        "                      padding=(2,2)),                # Cuántos pixeles de padding\n",
        "            nn.MaxPool2d(kernel_size=(3,3), stride=(2,2)), # Max Pooling\n",
        "            nn.ReLU()                            # Activación\n",
        "        )\n",
        "\n",
        "        # Input = 96 x 27 x 27 Output = 256 x 27 x 27 --> Max Pool = 256 x 13 x 13\n",
        "        self.conv2 = nn.Sequential(\n",
        "            nn.Conv2d(\n",
        "                      in_channels=96,\n",
        "                      out_channels=256,\n",
        "                      kernel_size=(5,5),\n",
        "                      stride=(1,1),\n",
        "                      padding=(2,2)),\n",
        "            nn.MaxPool2d(kernel_size=(3,3), stride=(2,2)),\n",
        "            nn.ReLU()\n",
        "        )\n",
        "        # Input = 256 x 13 x 13 Output = 384 x 13 x 13\n",
        "        self.conv3 = nn.Sequential(\n",
        "            nn.Conv2d(\n",
        "                      in_channels=256,\n",
        "                      out_channels=384,\n",
        "                      kernel_size=(3,3),\n",
        "                      stride=(1,1),\n",
        "                      padding=(1,1)),\n",
        "            nn.ReLU()\n",
        "        )\n",
        "        # Input = 384 x 13 x 13 Output = 384 x 13 x 13\n",
        "        self.conv4 = nn.Sequential(\n",
        "            nn.Conv2d(\n",
        "                      in_channels=384,\n",
        "                      out_channels=384,\n",
        "                      kernel_size=(3,3),\n",
        "                      stride=(1,1),\n",
        "                      padding=(1,1)),\n",
        "            nn.ReLU()\n",
        "        )\n",
        "        # Input = 384 x 13 x 13 Output = 256 x 13 x 13 --> MaxPool = 256 x 6 x 6\n",
        "        self.conv5 = nn.Sequential(\n",
        "            nn.Conv2d(\n",
        "                      in_channels=384,\n",
        "                      out_channels=256,\n",
        "                      kernel_size=(3,3),\n",
        "                      stride=(1,1),\n",
        "                      padding=(1,1)),\n",
        "            nn.MaxPool2d(kernel_size=(3,3), stride=(2,2)),\n",
        "            nn.ReLU()\n",
        "        )\n",
        "        ##\n",
        "        self.flat = nn.Flatten()    # Capa aplanamiento para poder vincular\n",
        "                                    # resultado convolucional con capas\n",
        "                                    # lineales.\n",
        "        # Bloques Fully Connected/MLP\n",
        "        # Input = 256 x 6 x 6 = 9216 Output = 4096\n",
        "        self.fc6 = nn.Sequential(\n",
        "                                  nn.Linear(9216, 4096),\n",
        "                                  nn.ReLU()\n",
        "                                  )\n",
        "        # Input = 4096 Output = 4096\n",
        "        self.fc7 = nn.Sequential(\n",
        "                                  nn.Linear(4096, 4096),\n",
        "                                  nn.ReLU()\n",
        "                                  )\n",
        "        # Input = 4096 Output = 1000\n",
        "        self.fc8 = nn.Sequential(\n",
        "                                  nn.Linear(4096, 1000)\n",
        "                                  )\n",
        "\n",
        "    def forward(self, x):        # Aquí armamos cómo se conectan las piezas\n",
        "                                 # Esta red es sencilla pues solo tenemos\n",
        "                                 # que conectar las piezas una detrás de la\n",
        "                                 # otra. No todas las redes son así.\n",
        "        x = self.conv1(x)\n",
        "        x = self.conv2(x)\n",
        "        x = self.conv3(x)\n",
        "        x = self.conv4(x)\n",
        "        x = self.conv5(x)\n",
        "        x = self.flat(x)\n",
        "        x = self.fc6(x)\n",
        "        x = self.fc7(x)\n",
        "        x = self.fc8(x)\n",
        "\n",
        "        return x\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JAGj6gsTLMlo"
      },
      "source": [
        "### ¿Cómo saber cuál va a ser la dimensionalidad de la salida de una capa convolucional?\n",
        "\n",
        "Esto suele ser un problema a la hora de armar una red convolucional, porque en algún momento (en particular al pasar a la sección fully connected de nuestra red) vamos a necesitar saber cuántas neuronas tiene nuestra red en un cierto punto. Por suerte, ¡existe una fórmula sencilla para calcularlo!\n",
        "\n",
        "* Sean $H, W$ el alto y ancho de nuestra imagen o de nuestros features convolucionales.\n",
        "* Sean $K_H, K_W$ los tamaños de los kernels asociados a $H$ y $W$.\n",
        "* Sean $S_H, S_W$ el *stride* asociado a $H$ y $W$.\n",
        "* Sea $P$ la cantidad de pixeles de padding.\n",
        "\n",
        "Entonces la dimensión de las caraterísticas de salida sería:\n",
        "\n",
        "$$O_H = \\lfloor\\frac{H - K_H + 2P}{S_H}\\rfloor + 1$$\n",
        "\n",
        "$$O_W =  \\lfloor\\frac{W - K_W + 2P}{S_W}\\rfloor + 1$$\n",
        "\n",
        "Por ejemplo para la primera capa de AlexNet tendríamos:\n",
        "\n",
        "$$O_H = \\lfloor \\frac{224 - 11 + 2\\cdot2}{4}\\rfloor + 1 = 55 $$\n",
        "$$O_W = \\lfloor\\frac{224 - 11 + 2\\cdot2}{4}\\rfloor + 1 = 55 $$\n",
        "\n",
        "¡Que es justo lo que esperábamos!\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0jBxicTtL-dA"
      },
      "source": [
        "#@title Calculadora de Dimensionalidad de Salida { run: \"auto\" }\n",
        "from math import floor   # Para redondear hacia abajo\n",
        "H =  13#@param {type:\"integer\"}\n",
        "W =  13#@param {type:\"integer\"}\n",
        "K =  3#@param {type:\"integer\"}\n",
        "S =   1#@param {type:\"integer\"}\n",
        "P =   1#@param {type:\"integer\"}\n",
        "\n",
        "output_H = floor((H - K + 2*P)/S) + 1\n",
        "output_W = floor((H - K + 2*P)/S) + 1\n",
        "\n",
        "print(\"Nuestro dimensionalidad de output es: ({}, {}).\".format(output_H, output_W))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bI0WJRUNZGGZ"
      },
      "source": [
        "### ¿Cómo calculamos la cantidad de neuronas a la salida de una capa convolucional?\n",
        "\n",
        "La cantidad de neuronas es de:\n",
        "\n",
        "$$ C_{out} \\cdot H \\cdot W  $$\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q3MyHcvpNDC-"
      },
      "source": [
        "6*6*256"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bQXEvBx0cXgE",
        "cellView": "form"
      },
      "source": [
        "#@title Calculadora de Neuronas { run: \"auto\" }\n",
        "C_out = 256 #@param {type:\"integer\"}\n",
        "H = 6 #@param {type:\"integer\"}\n",
        "W =  6#@param {type:\"integer\"}\n",
        "\n",
        "neuronas = C_out*H*W\n",
        "\n",
        "print(\"La cantidad de neuronas es de: {}.\".format(neuronas))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-L0eR7AFZovZ"
      },
      "source": [
        "### ¿Cómo calculamos la cantidad de parámetros asociados a una capa convolucional?\n",
        "\n",
        "* Sean $C_{in}$, $C_{out}$ los canales de entrada y salida de la capa.\n",
        "* Sea $K_H$, $K_W$ los tamaños del kernel de la capa.\n",
        "* $B$ es igual a $C_{out}$ en caso de usar *bias* en nuestra capa (lo más usual) y 0 en caso contrario.\n",
        "\n",
        "Entonces, la cantidad de parámetros es de:\n",
        "\n",
        "$$ C_{in} \\cdot C_{out} \\cdot K_H \\cdot K_W + B  $$\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TkPhehKbPJKf",
        "cellView": "form"
      },
      "source": [
        "#@title Calculadora de Cantidad de Parámetros { run: \"auto\" }\n",
        "# Aqui definimos características de una capa para calcular su número de parámetros\n",
        "C_in =  3#@param {type:\"integer\"}\n",
        "C_out = 96 #@param {type:\"integer\"}\n",
        "K_H = 11 #@param {type:\"integer\"}\n",
        "K_W = 11 #@param {type:\"integer\"}\n",
        "use_bias = False #@param [\"False\", \"True\"] {type:\"raw\"}\n",
        "\n",
        "if use_bias:\n",
        "    bias = C_out\n",
        "else:\n",
        "    bias = 0\n",
        "\n",
        "params = C_in*C_out*K_H*K_W + bias\n",
        "\n",
        "print(\"La cantidad de parámetros es: {}.\".format(params))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h22aa65Lu0sl"
      },
      "source": [
        "def contar_parametros(modelo):\n",
        "    contador = 0\n",
        "    for nombre, modulo in modelo.named_children():\n",
        "        params = sum(p.numel() for p in modulo.parameters() if p.requires_grad)\n",
        "        print(\"Cantidad Parámetros Capa '{}': {}.\".format(nombre, params))\n",
        "        contador += params\n",
        "\n",
        "    print(\"La cantidad total de parámetros es: {}.\".format(contador))\n",
        "    return contador"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p2pTea10vDHq"
      },
      "source": [
        "alex = AlexNet()\n",
        "contar_parametros(alex)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xpuNBQ2D6wYf"
      },
      "source": [
        "### Probando la Red\n",
        "\n",
        "Para verificar que la red funciona vamos a crear imágenes aleatorias y probaremos que se propaguen correctamente por la red. Si lanza un error, quiere decir que alguna de las capas que definimos no están entregando las dimensiones que esperábamos."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L-Qsg9iIqri9"
      },
      "source": [
        "alex = AlexNet() # Creamos una instancia de nuestra red\n",
        "datos_random = torch.randn((10, 3, 224, 224)).float() # Creamos un batch de 10 imágenes aleatorias\n",
        "resultado = alex(datos_random) # Metemos como input las imágenes a la red\n",
        "print(\"El resultado tiene forma: ({}, {})\".format(resultado.shape[0],resultado.shape[1]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wu5QE9A4yK0k"
      },
      "source": [
        "## Actividades\n",
        "\n",
        "Si bien fácilmente podemos reutilizar AlexNet para trabajar con imágenes de tamaño distinto a 224x224 cambiando el tamaño de las imágenes, esto es muy costoso pues estamos entrenando más parámetros de los que necesitamos en caso de entrenar con imágenes más pequeñas. Por lo tanto, le vamos a pedir que:\n",
        "\n",
        "1. Altere el modelo original para que trabaje en clasificación de 102 clases y no 1000. Llame a la clase de su modelo MiAlexNet.\n",
        "\n",
        "2. Altere la definición de MiAlexNet anterior para que tome como input imágenes de 3 x 64 x 64. Para esto, deberá alterar las capas *conv1* y *conv2* manteniendo el resto iguales. Llame a la clase de su modelo MiAlexNet. ¿Cómo cambia la cantidad de parámetros?\n",
        "\n",
        "3. Ahora usando el modelo original (o sea, sin incluir los cambios de la actividad 1 y 2) agregue una capa convolucional después de *conv5* de nombre *conv6* que reduzca la cantidad de filtros a 128. Altere *fc6* para hacer que esto funcione. Además, altere las capas lineales para que trabajen con 1024 dimensiones en vez de 4096. Recuerde que no sólo tiene que agrear la capa convolucional extra sino que hacer el cambio en la función *forward* para que ocupe *conv6*. Llame a la clase de su modelo MiAlexNet. ¿Cómo cambia la cantidad de parámetros?\n",
        "\n",
        "\n",
        "\n",
        "Una vez cree su clase MiAlexNet, ocupe el siguiente código para hacer el conteo de parámetros."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JFtpYvZFaOrP"
      },
      "source": [
        "modelo = MiAlexNet()\n",
        "modelo_antiguo = AlexNet()\n",
        "diferencia = contar_parametros(modelo_antiguo) - contar_parametros(modelo)\n",
        "print(\"La diferencia es de {} de parámetros.\".format(diferencia))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f69EIDXoEOkb"
      },
      "source": [
        "## Solución\n",
        "\n",
        "### Actividad 1"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DofT1HXWY2xk"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn           # Esto es PyTorch y su módulo de Redes Neuronales\n",
        "\n",
        "class MiAlexNet(nn.Module):               # Esta clase representa nuestro modelo\n",
        "\n",
        "    def __init__(self):   # Constructor, aquí armamos las piezas de nuestra red\n",
        "        super(MiAlexNet, self).__init__()\n",
        "        # Bloques Convolucionales\n",
        "        # Recordemos que los Bloques Convolucionales van a estar hechos de 3\n",
        "        # elementos: Convolución, Pooling y Activación.\n",
        "        # En este caso usaremos Convoluciones 2d, Max Pooling y ReLU\n",
        "\n",
        "        # Input = 3x 224 x 224 Output = 96 x 55 x 55 --> Max Pool = 96 x 27 x 27\n",
        "        self.conv1 = nn.Sequential(\n",
        "            nn.Conv2d(                           # Todo esto define a la Convolución\n",
        "                      in_channels=3,             # Filtros/Canales de Entrada (RGB)\n",
        "                      out_channels=96,           # Filtros/Canales de Salida\n",
        "                      kernel_size=(11,11),       # Tamaño de la Convolución\n",
        "                      stride=(4,4),              # Stride\n",
        "                      padding=(2,2)),            # Cuántos pixeles de padding\n",
        "            nn.MaxPool2d(kernel_size=(3,3), stride=(2,2)), # Max Pooling\n",
        "            nn.ReLU()                            # Activación\n",
        "        )\n",
        "\n",
        "        # Input = 96 x 27 x 27 Output = 256 x 27 x 27 --> Max Pool = 256 x 13 x 13\n",
        "        self.conv2 = nn.Sequential(\n",
        "            nn.Conv2d(\n",
        "                      in_channels=96,\n",
        "                      out_channels=256,\n",
        "                      kernel_size=(5,5),\n",
        "                      stride=(1,1),\n",
        "                      padding=(2,2)),\n",
        "            nn.MaxPool2d(kernel_size=(3,3), stride=(2,2)),\n",
        "            nn.ReLU()\n",
        "        )\n",
        "        # Input = 256 x 13 x 13 Output = 384 x 13 x 13\n",
        "        self.conv3 = nn.Sequential(\n",
        "            nn.Conv2d(\n",
        "                      in_channels=256,\n",
        "                      out_channels=384,\n",
        "                      kernel_size=(3,3),\n",
        "                      stride=(1,1),\n",
        "                      padding=(1,1)),\n",
        "            nn.ReLU()\n",
        "        )\n",
        "        # Input = 384 x 13 x 13 Output = 384 x 13 x 13\n",
        "        self.conv4 = nn.Sequential(\n",
        "            nn.Conv2d(\n",
        "                      in_channels=384,\n",
        "                      out_channels=384,\n",
        "                      kernel_size=(3,3),\n",
        "                      stride=(1,1),\n",
        "                      padding=(1,1)),\n",
        "            nn.ReLU()\n",
        "        )\n",
        "        # Input = 384 x 13 x 13 Output = 256 x 13 x 13 --> MaxPool = 256 x 6 x 6\n",
        "        self.conv5 = nn.Sequential(\n",
        "            nn.Conv2d(\n",
        "                      in_channels=384,\n",
        "                      out_channels=256,\n",
        "                      kernel_size=(3,3),\n",
        "                      stride=(1,1),\n",
        "                      padding=(1,1)),\n",
        "            nn.MaxPool2d(kernel_size=(3,3), stride=(2,2)),\n",
        "            nn.ReLU()\n",
        "        )\n",
        "\n",
        "        ##\n",
        "        self.flat = nn.Flatten()    # Capa aplanamiento para poder vincular\n",
        "                                    # resultado convolucional con capas\n",
        "                                    # lineales.\n",
        "        # Bloques Fully Connected/MLP\n",
        "        # Input = 256 x 6 x 6 = 9216 Output = 4096\n",
        "        self.fc6 = nn.Sequential(\n",
        "                                  nn.Linear(9216, 4096),\n",
        "                                  nn.ReLU()\n",
        "                                  )\n",
        "        # Input = 4096 Output = 4096\n",
        "        self.fc7 = nn.Sequential(\n",
        "                                  nn.Linear(4096, 4096),\n",
        "                                  nn.ReLU()\n",
        "                                  )\n",
        "        # Input = 4096 Output = 1000\n",
        "        self.fc8 = nn.Sequential(\n",
        "                                  nn.Linear(4096, 102)\n",
        "                                  )\n",
        "\n",
        "    def forward(self, x):        # Aquí armamos cómo se conectan las piezas\n",
        "                                 # Esta red es sencilla pues solo tenemos\n",
        "                                 # que conectar las piezas una detrás de la\n",
        "                                 # otra. No todas las redes son así.\n",
        "        x = self.conv1(x)\n",
        "        x = self.conv2(x)\n",
        "        x = self.conv3(x)\n",
        "        x = self.conv4(x)\n",
        "        x = self.conv5(x)\n",
        "        x = self.flat(x)\n",
        "        x = self.fc6(x)\n",
        "        x = self.fc7(x)\n",
        "        x = self.fc8(x)\n",
        "\n",
        "        return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WG8NwBpkYVXj"
      },
      "source": [
        "modelo = MiAlexNet()\n",
        "modelo_antiguo = AlexNet()\n",
        "diferencia = contar_parametros(modelo_antiguo) - contar_parametros(modelo)\n",
        "print(\"La diferencia es de {} de parámetros.\".format(diferencia))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cqR1cadlDMAq"
      },
      "source": [
        "## Parte 2 - Aplicaciones"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wJ2YnFmN1D3y"
      },
      "source": [
        "### 1. Imágenes - ¡Creemos un clasificador de distintos tipos de flores!\n",
        "\n",
        "En esta parte, vamos a trabajar con un conjunto de datos de 102 tipos de flores, el dataset Flowers (http://www.robots.ox.ac.uk/~vgg/data/flowers/102/index.html)), que nos ofrece 8.189 fotos distintas y es un conjunto de datos no tradicional. ¡Veamos cómo nos va!\n",
        "\n",
        "Todo lo necesario para trabajar de ahora en adelante lo pueden bajar a su sesión de Colab con el siguiente comando:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dMB7Z9_t_DYj"
      },
      "source": [
        "!wget https://www.dropbox.com/s/kda4klivyttdb71/lab1_CNN_IA.zip -q --show-progress\n",
        "!unzip lab1_CNN_IA.zip\n",
        "!tar -xzf flowers.tar.gz"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eveuiABO_LbG"
      },
      "source": [
        "Con eso, ya tenemos el dataset descomprimido en nuestro espacio de trabajo. Además, agregamos algunos archivos con código para lo que vamos a hacer más adelante (todavía no es necesario que entiendan el código, pero si te interesa, puedes inspeccionarlos).\n",
        "\n",
        "Veamos algunos ejemplos del dataset:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bx7sg7AHzleG"
      },
      "source": [
        "import torch\n",
        "from flowers import Flowers\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision.utils import make_grid\n",
        "from torchvision.transforms import ToTensor, Resize, Compose\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "## TODO ESTO LO ENTENDEREMOS EN EL LABORATORIO 2!\n",
        "transforms = Compose([Resize((224, 224)), ToTensor()])\n",
        "train_ds = Flowers(\"flowers_dataset/train\", transform=transforms)\n",
        "train_dl = DataLoader(train_ds, batch_size = 32, shuffle=True)\n",
        "test_ds = Flowers(\"flowers_dataset/test\", transform=transforms)\n",
        "test_dl = DataLoader(test_ds, batch_size = 1024)\n",
        "\n",
        "batch, _ = next(iter(train_dl))\n",
        "\n",
        "plt.figure(figsize=(15,30))\n",
        "foto = make_grid(batch, nrow=8).permute(1,2,0)\n",
        "\n",
        "r = plt.imshow(foto)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DlNRXP6aISMd"
      },
      "source": [
        "Vamos a ocupar la red MiAlexNet que definimos en la actividad 1 para enfrentar este problema. Dado que esto puede tomar un buen tiempo, nosotros ya entrenamos sus pesos. El cómo lo hicimos, lo veremos en detalle en el laboratorio de la próxima semana."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I-muamD2EvdE"
      },
      "source": [
        "#### A. Probemos el modelo sin entrenar"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tDT3YZXvEu85"
      },
      "source": [
        "modelo = MiAlexNet().cuda()             # Creamos Modelo, lo enviamos a GPU\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sjOp2LVGE-cs"
      },
      "source": [
        "Vamos a pasar todas las imágenes de test del dataset por nuestro modelo entrenado y vamos a calcular el accuracy del modelo. Esto es la cantidad de respuestas correctas sobre el total de imágenes probadas."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "21wndnLiE3GA"
      },
      "source": [
        "from test_model import test_model\n",
        "test_model(modelo, test_dl)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SXmHwtSrE64X"
      },
      "source": [
        "Anda mal, ¿verdad? Alrededor del 1% de exactitud en una tarea con 102 clases es básicamente apuntarle al azar. Probemos ahora con un modelo preentrenado."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pr1WmHWgJOGC"
      },
      "source": [
        "#### B. Carguemos los pesos preentrenados en nuestro modelo"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yHHE4XBcJOLx"
      },
      "source": [
        "pesos = torch.load(\"alexnet.pth\")       # Carga los pesos a una variable\n",
        "modelo.load_state_dict(pesos)           # Carga los pesos al modelo"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xbYEeCBJKsoK"
      },
      "source": [
        "#### C. Evaluemos el modelo entrenado\n",
        "\n",
        "Vamos a pasar todas las imágenes de test del dataset por nuestro modelo entrenado y vamos a calcular el ***accuracy*** del modelo. Esto es la cantidad de respuestas correctas sobre el total de imágenes probadas."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j01bVPNEK3tt"
      },
      "source": [
        "test_model(modelo, test_dl)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nK3M5Ss9Lqfe"
      },
      "source": [
        "¡El modelo obtiene alrededor de un 40% de accuracy en el set de test! ¡Bastante mejor que adivinar al azar!"
      ]
    }
  ]
}